---
title: "hw2"
output: html_document
---

sessionInfo()

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(eval = TRUE)
```

## 7.3.4 Exercises:
1. Explore the distribution of each of the x, y, and z variables in diamonds. What do you learn? Think about a diamond and how you might decide which dimension is the length, width, and depth.

    ```{r}
    library(ggplot2)
    ggplot(data = diamonds, mapping = aes(x = x)) +
      geom_freqpoly(binwidth = 0.01) +
      coord_cartesian(xlim = c(0,20)) -> p1

    ggplot(data = diamonds, mapping = aes(x = y)) +
      geom_freqpoly(binwidth = 0.01) +
      coord_cartesian(xlim = c(0,20)) -> p2

    ggplot(data = diamonds, mapping = aes(x = z)) +
      geom_freqpoly(binwidth = 0.01) +
      coord_cartesian(xlim = c(0,20)) -> p3

    source("http://peterhaschke.com/Code/multiplot.R")
    multiplot(p1, p2, p3, cols=1)
    ```
The plot for z shows measurements significantly shorter than those found in x and y, while x and y both look to be distributed very similarly. y and z both appear to have outliers. It makes sense to conclude that z is depth, while x is length, y is width (but x and y could be vice versa, as it is hard to distinguish between the two).

2. Explore the distribution of price. Do you discover anything unusual or surprising? (Hint: Carefully think about the binwidth and make sure you try a wide range of values.)


    ```{r}
    library(dplyr)

      # entire plot shows an unusual bump around ~8000.
    ggplot(data = diamonds, mapping = aes(x = price)) +
      geom_freqpoly(binwidth = 1) -> p1
    
      # zoom in on lower section and discover no price at ~1500.
    lower <- diamonds %>% 
      filter(price < 2000)
    ggplot(data = lower, mapping = aes(x = price)) +
      geom_histogram(binwidth = 10) -> p2
    
      # zoom in on mid-section.
    bigger <- diamonds %>%
      filter(price <10000 & price > 6000)
    ggplot(data = bigger, mapping = aes(x = price)) +
      geom_histogram(binwidth = 50) -> p3
    
      # zoom in on upper section.
    upper <- diamonds %>% 
      filter(price >5000)
    ggplot(data = upper, mapping = aes(x = price)) +
      geom_histogram(binwidth = 10) -> p4

    multiplot(p1, p2, p3, p4, cols=2)
```

We notice generally that there are exponentially more lower priced diamonds than expensive diamonds. The top left graph shows a slight increase in diamonds priced around ~8000. The lower left graph shows an unusual absence of diamonds priced at ~1500.

3. How many diamonds are 0.99 carat? How many are 1 carat? What do you think is the cause of the difference?

    ```{r}
    unusual <- diamonds %>% 
      filter(carat == 1 | carat == 0.99) %>% 
      count(carat)
    unusual
    ```

There are 1558 observed 1.00 carat diamonds, compared to 23 observed 0.99 carat diamonds. That is roughly 68 times more 1.00 carat diamonds than 0.99 carat diamonds. There is likely a big price descrepancy in diamond pricing once they hit the 1.00 carat threshold. Thus, those at 0.99 carat may simply be rounded up to 1.00 for marketability.

4. Compare and contrast coord_cartesian() vs xlim() or ylim() when zooming in on a histogram. What happens if you leave binwidth unset? What happens if you try and zoom so only half a bar shows?

    ```{r}
      # xlim() or ylim().
    ggplot(diamonds) +
      geom_histogram(mapping = aes(x = price)) +
      xlim(1000, 6000) +
      ylim(0, 3500) -> p1
      # coord_cartesian()
    ggplot(diamonds) +
      geom_histogram(mapping = aes(x = price)) +
      coord_cartesian(xlim = c(1000, 6000), ylim = c(0, 3500)) -> p2
    
    multiplot(p2, p1, cols = 1)
    ```

Using xlim and ylim functions alone, drops values outside of the xlim, ylim range, before calculating the histogram. This is why the xlim, ylim plot has a lower count than the coord_cartesian plot. Whereas, cartesian_coord does not drop any values, and only "zooms" into the limits defined by xlim and ylim.
    ```{r}
      # zooming in so only half a bar shows.
      # xlim() or ylim().
    ggplot(diamonds) +
      geom_histogram(mapping = aes(x = price)) +
      xlim(5999.5, 6000) +
      ylim(0, 3500) -> p1
      # coord_cartesian()
    ggplot(diamonds) +
      geom_histogram(mapping = aes(x = price)) +
      coord_cartesian(xlim = c(5999.5, 6000), ylim = c(0, 3500)) -> p2    
    multiplot(p2, p1, cols = 1)
    ```

This example shows that if you try to zoom into half of a bar using coord_cartesian, you will see a solid block along the x-values, at the appropriate count. Whereas, using the xlim() and ylim() functions alone, you will see an empty plot because values outside of the specific price range (in this case 5999.5-6000) will be dropped before calculating and drawing the histogram.

## 7.4.1:

What happens to missing values in a histogram? What happens to missing values in a bar chart? Why is there a difference?

```{r}
  # Creating a subset from diamonds, removing lower and upper length.
diamondMidLength <- diamonds %>%
  mutate(x = ifelse(x < 3 | x > 20, NA, x))
ggplot(diamondMidLength) +
  geom_histogram(mapping = aes(x = x)) -> p1

  # Creating a subset from
n<-nrow(diamonds)
diamondMidClarity <- diamonds %>%
  mutate( clarity = if_else(rnorm(n) < 0.0001, NA_character_, as.character(cut))) 
ggplot(diamondMidClarity) +
  geom_bar(mapping = aes(x = clarity)) -> p2

multiplot(p1, p2, cols = 1)
```
When attempting to plot a subset of data diamondMidLength with missing values (NA), the missing values are first removed, before the number of observations in each bin is calculated. There will be a warning message that alerts you "Removed 8 rows containing non-finite values (stat_bin)". When using geom_bar to plot a subset of categorical data DiamondMidClarity, the "NA" values are treated as another gradation of clarity and are subsequently plotted as another category in the bar plot.


```{r}
ranVals <- rnorm(n = 100, mean = 10, sd = 10)
  # In this case, which elements of (ranVals %in% sample) are TRUE:
  # Randomly chooses 20 indices to be replaced with NA
miss <- which(ranVals %in% sample(ranVals,20))
ranVals[miss] <- NA

mean(ranVals, na.rm = FALSE)
sum(ranVals, na.rm = FALSE)

mean(ranVals, na.rm = TRUE)
sum(ranVals, na.rm = TRUE)
```
When attempting to calculate the mean or sum of a vector with NA values, the result is NA. If we utilize na.rm = TRUE, the NA observations are ommitted from the calculation, allowing us to have a numerical answer.

## 7.5.1.1:

Use what you’ve learned to improve the visualisation of the departure times of cancelled vs. non-cancelled flights.
    ```{r}
    flightSub <- nycflights13::flights %>%
      # If the departure time is na = canceled flight.
    mutate(canceledFlight = is.na(dep_time),
             # Calculating time on a 24 hour scale.
           min = (sched_dep_time %% 100) / 60,
           hour = sched_dep_time %/% 100,
           departureTime = hour + min
          ) %>%
    ggplot() + geom_boxplot(mapping = aes(y = departureTime, x = canceledFlight))
    flightSub
    ```
Here we use a boxplot to visualize the departure time distribution for canceled and non-canceled fights. The median departure time and IQR of canceled flights are later in the day than those of flights that were not canceled. We also see an outlier point at approximately 1 AM for a canceled flight.


2) What variable in the diamonds dataset is most important for predicting the price of a diamond? How is that variable correlated with cut? Why does the combination of those two relationships lead to lower quality diamonds being more expensive?


3) Install the ggstance package, and create a horizontal boxplot. How does this compare to using coord_flip()?

    ```{r}
    ## install.packages("ggstance")
    library(ggstance)
    ggplot(data = mpg) +
      geom_boxplot(mapping = aes(x = reorder(class, hwy, FUN = median), y = hwy)
                   ) -> p1
      # Usage of coord_flip() function to show vehicle classes on the y axis.
    ggplot(data = mpg) +
      geom_boxplot(mapping = aes(x = reorder(class, hwy, FUN = median), y = hwy)
                   ) + coord_flip() -> p2
      # Usage of ggstance, requires switching the assignment of x and y variables. 
    ggplot(data = mpg) +
      geom_boxploth(mapping = aes(x = hwy,
                    y = reorder(class, hwy, FUN = median))) -> p3
    
    multiplot(p1, p2, p3, numcol = 1)
    ```
Originally we have the boxplot defined with the classes of vehicles on the x axis, and hwy on the y axis. Thus when we implement coord_flip, the result is vehicles on the y axis and hwy on the x axis. By installing ggstance and using the function geom_boxploth, to directly plot a horizontal boxplot, we define hwy on the x axis and vehicle classes on the y.

4) One problem with boxplots is that they were developed in an era of much smaller datasets and tend to display a prohibitively large number of “outlying values”. One approach to remedy this problem is the letter value plot. Install the lvplot package, and try using geom_lv() to display the distribution of price vs cut. What do you learn? How do you interpret the plots?

    ```{r}
      # install.packages("lvplot")
    library(lvplot)
    ggplot(diamonds, aes(x = cut, y = price)) +
    geom_lv()
    ```
 
The letter value plot extends the number of "letter value" statistics used. For particularly large datasets (like this one), it provides more visual information on the tail behavior, and displays fewer outliers. In general, we can see as the cut quality increases from fair to ideal, the upper portion of the plot increases in width at the higher prices. This is intuitive, as "ideal" cut diamonds, would demand a higher price. We can also notice that the middle to lower portion of "fair" cut diamonds appears to be comparable-- if not even greater-- than higher quality "cut" diamonds. This supports the fact that the "fair" diamonds being more expensive on average.

5)Compare and contrast geom_violin() with a facetted geom_histogram(), or a coloured geom_freqpoly(). What are the pros and cons of each method?
    ```{r}
# Compare and contrast geom_violin() with a facetted geom_histogram(), or a coloured geom_freqpoly(). What are the pros and cons of each method?

ggplot(data = diamonds, mapping = aes(x = price, y = ..density.., colour = cut)) +
  geom_freqpoly(binwidth = 500)

ggplot(data = diamonds, mapping = aes(x = price, colour = cut)) +
  geom_histogram(binwidth = 50) +
  facet_wrap(~cut, ncol = 1, scales = "free_y")

ggplot(data = diamonds, mapping = aes(x = cut, y = price)) +
  geom_violin(aes(fill = cut)) +
  coord_flip()
    ```

Geom_freqpoly allows for easy determination of the highest density of price points for each cut of diamond. However, because the lines are overlapping, it is difficult to say much about individual distributions of cuts, and how they relate to one another. Because each histogram is separated, geom_histogram makes it easy to distinguish between differences in overall shape of distribution, and more specifically: variance and skewness. Similarly, geom_violin is useful for comparing distribution of prices, across cuts.

6) If you have a small dataset, it’s sometimes useful to use geom_jitter() to see the relationship between a continuous and categorical variable. The ggbeeswarm package provides a number of methods similar to geom_jitter(). List them and briefly describe what each one does.

    ```{r}
      # install.packages("ggbeeswarm")
    library("ggbeeswarm")
    ggplot(data = mpg) +
      geom_jitter(mapping = aes(x = reorder(class, hwy, FUN = median), y = hwy)) -> p1

    ggplot(data = mpg) +
      geom_quasirandom(mapping = aes(x = reorder(class, hwy, FUN = median), y = hwy)) -> p2

    ggplot(data = mpg) +
      geom_beeswarm(mapping = aes(x = reorder(class, hwy, FUN = median), y = hwy)) -> p3

    multiplot(p1, p2, p3, col = 1)
    ```
Geom_jitter allows us to see the relationship between a continuous and categorical variable by adding a small amount of random variation to each point-- handles the overplotting problem created by the discreteness in smaller datasets. Geom_beeswarm is closest in shape (most compact) to geom_violin, with points offset from each other. Geom_quasirandom plots are created with points spaced further away, randomly via different methods including: tukey, tukeyDense, smiley, frowney. In appearance, geom_quasirandom is a jitter/beeswarm hybrid in terms of spacing.



